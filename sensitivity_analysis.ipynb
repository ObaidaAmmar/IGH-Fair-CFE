{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis for Alzheimer's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SensitivityAnalysis import SensitivityAnalysis\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Pre-trained Model\n",
    "model = pickle.load(open('Alzheimer/Models/random_forest_classifier.sav', 'rb'))\n",
    "# Load whole Alzheimer dataset\n",
    "dataset = pd.read_csv(\"Alzheimer/Dataset/alzheimer_disease.csv\")\n",
    "# Select only the features that are used in the model\n",
    "dataset = dataset[['Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment', 'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Diagnosis']]\n",
    "# Load the affected dataset (possible values: cluster_1.csv, cluster_2.csv, cluster_3.csv, prediceted_target_1_instances.csv)\n",
    "affected_dataset = pd.read_csv(\"Alzheimer/Dataset/cluster_2.csv\") \n",
    "\n",
    "# For RL Framework\n",
    "# Features to change and its types used in RL framework\n",
    "features_to_change = [\"FunctionalAssessment\", \"ADL\", \"MMSE\"]\n",
    "features_types = [\"con\", \"con\", \"con\"]\n",
    "mins = [0, 0, 0] # Minimum values for the features to change\n",
    "maxs = [10, 10, 30] # Maximum values for the features to change\n",
    "\n",
    "# Counterfactuals generated by the RL framework\n",
    "counterfactuals = [[2.049, 2.846, 8.077], [2.734, 1.763, 9.127], [0.299, 3.581, 9.525], [2.157, 2.511, 21.475]]\n",
    "desired_label = 0\n",
    "\n",
    "\n",
    "# For DiCE\n",
    "# Alzheimer's Features types to be used in DiCE\n",
    "dataset_features_types = [\"con\", \"cat\", \"cat\", \"ord\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"con\", \"cat\", \"cat\", \"con\"]\n",
    "outcome = \"Diagnosis\"\n",
    "\n",
    "# For Nice\n",
    "X = dataset.drop('Diagnosis', axis=1)\n",
    "y = dataset['Diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.20, random_state=40)\n",
    "predict_fn = lambda x: model.predict_proba(x)\n",
    "\n",
    "# True: if you want to generate CFs using DiCE and Nice and calculate its gower distance\n",
    "# False: if you want to find Gower distance for the RL generated CFs\n",
    "dice_nice = True \n",
    "\n",
    "# Sensitivity Analysis\n",
    "sa = SensitivityAnalysis(dataset, affected_dataset, features_to_change, features_types, dataset_features_types, mins, maxs, model, desired_label, dice_nice, model_type='sklearn')\n",
    "sa.set_dice_data(outcome)\n",
    "sa.set_nice_data(X_train, y_train, predict_fn)\n",
    "\n",
    "# If you want to find best CF (RL Framework) for each individual and its gower distance\n",
    "# output_csv_path = \"SensitivityAnalysis/Alzheimer/FairnessMetric/cluster_0.csv\" , instead of FairnessMetric use (EF-Micro, EF-Macro, ECR or EF-ECR)\n",
    "output_csv_path = \"SensitivityAnalysis/Alzheimer/DiceNice/cluster_2.csv\"\n",
    "\n",
    "sa.find_best_cf_for_individuals(affected_dataset, counterfactuals, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis for Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SensitivityAnalysis import SensitivityAnalysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "# Load Pre-trained Mode\n",
    "model = pickle.load(open('Adult/Models/random_forest_classifier.sav', 'rb'))\n",
    "# Load whole Adult dataset\n",
    "dataset = pd.read_csv(\"Adult/Dataset/adult.csv\")\n",
    "# Load the affected dataset (possible values: cluster_1.csv, cluster_2.csv, cluster_3.csv, prediceted_target_0_instances.csv)\n",
    "affected_dataset = pd.read_csv(\"Adult/Dataset/cluster_2.csv\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.replace('?', np.nan)\n",
    "dataset.dropna(how='any', inplace=True)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset['income']= dataset['income'].replace({'<=50K':0, '>50K':1})\n",
    "dataset['race'] = dataset['race'].apply(lambda x: 0 if x == 'White' else 1)\n",
    "dataset['gender'] = dataset['gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "dataset.rename(columns={'gender': 'sex'}, inplace=True)\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['workclass'] = label_encoder.fit_transform(dataset['workclass'])\n",
    "dataset['education'] = label_encoder.fit_transform(dataset['education'])\n",
    "dataset['marital-status'] = label_encoder.fit_transform(dataset['marital-status'])\n",
    "dataset['occupation'] = label_encoder.fit_transform(dataset['occupation'])\n",
    "dataset['relationship'] = label_encoder.fit_transform(dataset['relationship'])\n",
    "dataset['native-country'] = label_encoder.fit_transform(dataset['native-country'])\n",
    "\n",
    "# For RL Framework\n",
    "# Features to change and its types used in RL framework\n",
    "features_to_change = [\"capital-gain\", \"hours-per-week\", \"educational-num\"]\n",
    "features_types = [\"con\", \"con\", \"ord\"]\n",
    "mins = [0, 1, 1] # Minimum values for the features to change\n",
    "maxs = [99999, 99, 16] # Maximum values for the features to change\n",
    "\n",
    "# Counterfactuals generated by the RL framework\n",
    "counterfactuals = [[9675, 5, 3], [10816, 0, 1], [8173, 10, 4]]\n",
    "desired_label = 1\n",
    "\n",
    "# For DiCE\n",
    "# Adult Features types to be used in DiCE\n",
    "dataset_features_types = [\"con\", \"cat\", \"con\", \"ord\", \"ord\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"con\", \"con\", \"con\", \"cat\"]\n",
    "outcome = \"income\"\n",
    "\n",
    "# For Nice\n",
    "X = dataset.drop('income', axis=1)\n",
    "y = dataset['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.20, random_state=40, stratify=y)\n",
    "predict_fn = lambda x: model.predict_proba(x)\n",
    "\n",
    "# True: if you want to generate CFs using DiCE and Nice and calculate its gower distance\n",
    "# False: if you want to find Gower distance for the RL generated CFs\n",
    "dice_nice = True\n",
    "\n",
    "# Sensitivity Analysis\n",
    "sa = SensitivityAnalysis(dataset, affected_dataset, features_to_change, features_types, mins, maxs, model, desired_label, dice_nice, model_type='sklearn')\n",
    "sa.set_dice_data(dataset_features_types, outcome)\n",
    "sa.set_nice_data(X_train, y_train, predict_fn, dataset_features_types)\n",
    "\n",
    "# If you want to find best CF (RL Framework) for each individual and its gower distance\n",
    "# output_csv_path = \"SensitivityAnalysis/Adult/FairnessMetric/cluster_0.csv\" , instead of FairnessMetric use (EF-Micro, EF-Macro, ECR or EF-ECR)\n",
    "output_csv_path = \"SensitivityAnalysis/Adult/DiceNice/cluster_2.csv\"\n",
    "\n",
    "sa.find_best_cf_for_individuals(affected_dataset, counterfactuals, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Mean Gower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of a column in a dataset across all rows\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from Alzheimer's or Adult\n",
    "data = pd.read_csv('SensitivityAnalysis/Adult/DiceNice/cluster_2.csv')\n",
    "tmp = \"DiCE Gower\" # \"NICE CF Gower\" / \"DiCE CF Gower\" / \"GFCF Gower\"\n",
    "\n",
    "# Ensure \"Gower\" column exists\n",
    "if tmp in data.columns:\n",
    "    # Convert the column to numeric, coercing errors to NaN (handles non-numeric values)\n",
    "    data[tmp] = pd.to_numeric(data[tmp], errors=\"coerce\")\n",
    "\n",
    "    # Remove rows where \"DiCE CF Gower\" is NaN or infinity\n",
    "    filtered_data = data[(~data[tmp].isna()) & (~data[tmp].isin([np.inf, -np.inf]))]\n",
    "\n",
    "    print(filtered_data[tmp])\n",
    "    print(filtered_data.shape[0])\n",
    "\n",
    "    # Calculate the mean of the \"DiCE CF Gower\" column\n",
    "    mean_value = filtered_data[tmp].mean()\n",
    "    print(f\"The mean of '{tmp}' is: {mean_value}\")\n",
    "else:\n",
    "    print(f\"The column '{tmp}' does not exist in the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiceNice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
